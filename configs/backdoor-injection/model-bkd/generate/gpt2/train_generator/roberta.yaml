save_dir: "./results/backdoor_injection/model_bkd/generate/gpt2/train_generator/roberta"
seed: 42
---
dataset:
        task: [sst2, offenseval, twitter, agnews]
        num_labels: [2, 2, 2, 4]
---
generator:
        type: "generator"
        name: "gpt2"
        max_length: 128
        max_new_tokens: 63
        decode_strategy: "sample"
---
classifier:
        type: "classifier"
        name: "roberta-base"
        max_length: 192  # max_length + max_new_tokens + 1
---
poisoner:
        method: "model_bkd"   
        target_label: 0   
---
trainer:
        method: "model_bkd2" 
        epochs: 10
        batch_size: 20
        lr: "2e-5"
        weight_decay: 0.01
        warm_up_epochs: 3
        gradient_accumulation_steps: 4
        max_grad_norm: 1.0
        gumbel_temp_max: 0.5
        gumbel_temp_min: 0.1

        
        